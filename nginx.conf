
# Nginx Configuration for Valet Key Project
# Layer 1: Nginx-level Rate Limiting (First Line of Defense)
events {}
# Define rate limit zones
http {
limit_req_zone $binary_remote_addr zone=login_limit:10m rate=5r/m;
limit_req_zone $binary_remote_addr zone=upload_limit:10m rate=30r/m;
limit_req_zone $binary_remote_addr zone=public_limit:10m rate=50r/m;
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;

# Connection limit per IP
limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

# Upstream backend server
upstream backend {
    # Use least_conn for better load distribution
    least_conn;
    
    # Backend servers (add more for horizontal scaling)
    server localhost:8080 max_fails=3 fail_timeout=30s;
    # server localhost:8081 max_fails=3 fail_timeout=30s;
    # server localhost:8082 max_fails=3 fail_timeout=30s;
    
    # Enable keepalive connections
    keepalive 32;
}

server {
    listen 80;
    server_name localhost;

    # Maximum upload size (matches backend configuration)
    client_max_body_size 1024M;
    client_body_buffer_size 128k;
    client_body_timeout 300s;

    # Proxy timeouts for large file uploads
    proxy_connect_timeout 300s;
    proxy_send_timeout 300s;
    proxy_read_timeout 300s;
    send_timeout 300s;

    # Connection limit: max 10 concurrent connections per IP
    limit_conn conn_limit 10;

    # Enable gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss application/rss+xml font/truetype font/opentype application/vnd.ms-fontobject image/svg+xml;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "no-referrer-when-downgrade" always;

    # ===================================
    # AUTHENTICATION ENDPOINTS (CRITICAL)
    # ===================================
    location = /login {
        # Rate limit: 5 requests per minute per IP
        limit_req zone=login_limit burst=5 nodelay;
        
        # Log failed login attempts
        access_log /var/log/nginx/login_access.log combined;
        error_log /var/log/nginx/login_error.log warn;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # ===================================
    # FILE UPLOAD ENDPOINTS
    # ===================================
    # Direct Azure Upload Endpoints (SAS URL generation and confirmation)
    # Note: Actual file upload goes directly to Azure, not through backend
    location ~ ^/api/files/upload/(sas-url|confirm) {
        # Rate limit: 30 requests per minute per IP
        limit_req zone=upload_limit burst=5 nodelay;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Resume Upload Endpoints (chunked uploads)
    location ~ ^/api/files/upload/(initiate|chunk|complete) {
        # Rate limit: 30 requests per minute per IP
        limit_req zone=upload_limit burst=5 nodelay;
        
        # Disable request buffering for large files
        proxy_request_buffering off;
        
        # Special timeout for uploads
        proxy_read_timeout 600s;
        proxy_send_timeout 600s;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Pass upload progress
        proxy_set_header X-Accel-Buffering no;
    }

    # Legacy Upload Endpoints (kept for backward compatibility)
    # Note: Not used in new implementation (direct Azure upload preferred)
    location ~ ^/api/files/upload(/batch)?$ {
        # Rate limit: 30 requests per minute per IP
        limit_req zone=upload_limit burst=5 nodelay;
        
        # Disable request buffering for large files
        proxy_request_buffering off;
        
        # Special timeout for uploads
        proxy_read_timeout 600s;
        proxy_send_timeout 600s;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Pass upload progress
        proxy_set_header X-Accel-Buffering no;
    }

    # Async Upload Endpoint (for very large files > 100MB)
    location = /api/async-upload/initiate {
        # Rate limit: 30 requests per minute per IP
        limit_req zone=upload_limit burst=5 nodelay;
        
        # Disable request buffering for large files
        proxy_request_buffering off;
        
        # Special timeout for uploads
        proxy_read_timeout 600s;
        proxy_send_timeout 600s;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Pass upload progress
        proxy_set_header X-Accel-Buffering no;
    }

    # ===================================
    # PUBLIC FILE ACCESS (HIGH RISK)
    # ===================================
    location ~ ^/api/public/ {
        # Rate limit: 50 requests per minute per IP
        limit_req zone=public_limit burst=10 nodelay;

        # Cache static content
        proxy_cache_valid 200 10m;
        proxy_cache_bypass $http_cache_control;
        add_header X-Cache-Status $upstream_cache_status;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # ===================================
    # GENERAL API ENDPOINTS
    # ===================================
    location /api/ {
        # Rate limit: 100 requests per minute per IP
        limit_req zone=api_limit burst=20 nodelay;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Enable keepalive to backend
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }

    # ===================================
    # WEBSOCKET ENDPOINT (No rate limit)
    # ===================================
    location /ws {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # WebSocket timeout
        proxy_read_timeout 86400s;
        proxy_send_timeout 86400s;
    }

    # ===================================
    # HEALTH/METRICS ENDPOINTS (No rate limit)
    # ===================================
    location /actuator/ {
        # Optional: restrict to internal IPs only
        # allow 127.0.0.1;
        # deny all;

        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # ===================================
    # STATIC FILES (Frontend)
    # ===================================
    location / {
        # Serve frontend static files
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ /index.html;

        # Cache static assets
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 30d;
            add_header Cache-Control "public, immutable";
        }
    }

    # ===================================
    # ERROR PAGES
    # ===================================
    error_page 429 /429.html;
    location = /429.html {
        root /usr/share/nginx/html;
        internal;
    }

    error_page 502 503 504 /50x.html;
    location = /50x.html {
        root /usr/share/nginx/html;
        internal;
    }
}
}

# ===================================
# ADDITIONAL NOTES
# ===================================
# 
# 3-LAYER RATE LIMITING ARCHITECTURE:
# 
# Layer 1 (Nginx): Basic IP-based rate limiting
#   - Protects against DDoS and simple attacks
#   - Fast, minimal overhead
#   - Applies before reaching backend
# 
# Layer 2 (Bucket4j): Application-level per-user rate limiting
#   - More granular control (per user, per endpoint)
#   - Considers authentication and user context
#   - Implemented in RateLimitInterceptor.java
#
# Layer 3 (Resilience4j): Service-level protection
#   - Circuit breaker for Azure calls
#   - Retry logic for transient failures
#   - Protects backend from cascading failures
# 
# DEPLOYMENT:
# 1. Copy this file to /etc/nginx/nginx.conf or /etc/nginx/sites-available/
# 2. Create custom error pages in /usr/share/nginx/html/
# 3. Test configuration: sudo nginx -t
# 4. Reload: sudo systemctl reload nginx
# 5. Monitor: tail -f /var/log/nginx/access.log


